---
title: "STATS 506 Group Project"
author: "Group 13 (Jinwen Cao, Olivia Hackworth, Xian Zhang)"
date: "Dec.06 2018"
output: html_document
---

The purpose of our group is to compare the performance between Probit Regression and Logistic Regression in 'Communities and Crime' Data Set with Stata, R and Python. 

<font size="5">Introduction to Probit Regression and Logistic Regression</font><br /> 

When dealing with the dataset that includes the binary dependent variable, the logistic regression can also be called logit model. The logit model and probit model are both used to do nonlinear estimation on dichotomous or binary dependent variables. These two models both share the same basic idea of applying a link function to binary dependent variables to transform it to continuous variables on the set of real numbers. After the transformation, linear regression can be applied to the new data with the original independent variables and transformed dependent variables. The main difference between the logit model and probit model is the link function they used. The link function of probit model is the inversed cumulative distribution function of standard normal distribution \[\Phi^{-1}(p)\] The link function of logit model is the log of odds ratio (log odds) \[log\frac{p}{1-p}\] The logit function is very similar to standard normal distribution while the normal distribution has heavier tail than logit function. After the transformation, the maximum likelihood estimation will be adopted to estimate the parameters that can maximize the probability of what have been observed.


<font size="5">Description of Data</font><br /> 

The dataset we used is ['Communities and Crime'](https://archive.ics.uci.edu/ml/datasets/Communities+and+Crime) Data Set from UCI Machine Learning Repository. The data combines socio-economic data from the 1990 US Census, law enforcement data from the 1990 US LEMAS survey, and crime data from the 1995 FBI UCR.

We chose ViolentCrimesPerPop as response variable and Population, perCapInc, PctPopUnderPov, pctUrban as predictor variables.However, ViolentCrimesPerPop is a continuous variable while both logit and probit regression require a binary outcome. We made our response binary by classifying observations of 0.5 or higher as high crime communities and observations of less than 0.5 as low crime communities. We chose 0.5 as the cut off because it corresponds to 1 violent crime for every 200,000 people in the community. Our task is to figure out what is more likely to cause high violent crime rate based on their personal information. The probit and logistic regression are carried out to handle this challenge.

<font size="5">Outline of Examples</font><br /> 

Below are three examples using probit and logit regression. They all include a probit regression, and a discussion of results and diagnostics followed by a logit regression, with a similar discussion. One of the diagnostic tests we run is the Hosmer-Lemeshow (HL) test which is also dicussed by Group 5. You could look at their project if you would like more examples. 

The different packages have different capabilities for tests, so the examples don't match exactly. First is an example in Python created by Jinwen. She created her own function to run the HL test, so look there for a function by hand and more technical information about the test. Next is an example in R by Xian. This example expands on Jinwen's. Last is an example in Stata by Olivia. Stata has the easiest access to the tests and statistics we were interested in, so this example includes the longest discussion. 


```{r, include = FALSE}
library(aod)
library(ggplot2)
library(dplyr)
library(ResourceSelection)
library(tidyverse)
library(knitr)
```
<font size="5"> R Part</font><br />

<font size="4"> 1) Loading data</font><br />

The data set is a subset of the original data that only includes "Population, perCapInc, PctPopUnderPov, pctUrban" as predictor variables. The response variable "highcrime" was made by taking ViolentCrimesPerPop and classifying observations of 0.5 or higher as high crime communities (1) and observations of less than 0.5 as low crime communities (0).

```{r, include=FALSE}
communities.data = read.csv("~/communities.data.txt", header=FALSE)
df3=select(communities.data,c(6,17,26,34,128))
df3=na.omit(df3)
Highcrime=rep(0,1994)
for(i in 1:1994){
  if(df3$V128[i]>0.5){
    Highcrime[i]=1
  }
}
name=c('Population','PctUrban', 'PerCapInc', 'PctPopUnderPov','ViolentCrimesPerPop')
inf=c('Population for community', 'percentage of people living in areas classified as urban','per capita income','percentage of people under the poverty level','total number of violent crimes per 100K popuation')
c1=cbind(name,inf)


names(df3)[names(df3)=="V6"]="Population"
names(df3)[names(df3)=="V17"]="PctUrban"
names(df3)[names(df3)=="V26"]="PerCapInc"
names(df3)[names(df3)=="V34"]="PctPopUnderPov"
names(df3)[names(df3)=="V128"]="ViolentCrimesPerPop"

df3=cbind(df3,Highcrime)

```

```{r}
kable(c1)
head(df3)
```

<font size="4"> 2) Probit model</font><br />

The code below estimates a probit regression model using the glm (generalized linear model) function.

```{r}
myprobit = glm(Highcrime ~Population+PctUrban+PerCapInc+PctPopUnderPov, family = binomial(link = "probit"), data = df3)
summary(myprobit)
```

The deviance residuals are a measure of model fit. This part of output shows the distribution of the deviance residuals for individual cases used in the model. The next part of the output shows the coefficients, their standard errors, the z-statistic and the associated p-values.

From the result we can see that "Population, PctPopUnderPov, pctUrban" are statistically significant while "perCapInc" doesn't have good performance. 

Below the table of coefficients are fit indices, including the null and deviance residuals and the AIC. Later we show an example of how you can use these values to help assess model fit. In addition, we can obtain confidence intervals for the coefficient estimates that is based on the standard error and the normal assumption.

```{r}
confint(myprobit)
```

We can test for an overall effect of "Population, PctPopUnderPov, pctUrban, perCapInc" using the wald.test function.

```{r}
wald.test(b = coef(myprobit), Sigma = vcov(myprobit), Terms = 2:5)
```

The chi-squared test statistic of 322.7 with 4 degrees of freedom is associated with a p-value of less than 0.001 indicating that the overall effect of rank is statistically significant. Then we use testing data set and predicted probabilities to help us understand the model. 

```{r}
df3[, c("p", "se")] = predict(myprobit, df3, type = "response", se.fit = TRUE)[-3]
with(myprobit, pchisq(null.deviance - deviance, df.null - df.residual, lower.tail = FALSE))
```

We can also see measures of how well our model fits. The chi-square of 305.8052 with 3 degrees of freedom and an associated p-value of less than 0.001 tells us that our model as a whole fits significantly better than an empty model.

Then we took the Hosmer-Lemeshow test to compare the result of probit model with logistic model. 

```{r}
hoslem.test(myprobit$y, fitted(myprobit), g=5)
```

The group number is set as 5 because this will be easy to compare the results with other language. The p-value is 1.41e-06 which is very close to zero. This means we have reject the null hypothesis for the HL test that the model has a good fit. The H-L test is not reliable. Therefore we should trust the result of Wald test instead of the H-L test. 

<font size="4"> 3) Logistic model</font><br />

Just like the probit regression, the code below estimates a probit regression model using the glm (generalized linear model) function.

```{r}
mylogit=glm(Highcrime ~Population+PctUrban+PerCapInc+PctPopUnderPov, data = df3, family = "binomial")
summary(mylogit)
confint.default(mylogit)
```

We can see that Logistic model has similar result as the Probit model. All the predictors are statistically significant except for perCapInc. (The p-value for perCapInc in Logistic model is lower than in Probit model)

```{r}
wald.test(b = coef(mylogit), Sigma = vcov(mylogit), Terms = 2:5)
```

The chi-squared test statistic of 285.1 ( a little bit lower than the one in probit regression) with 4 degrees of freedom is associated with a p-value of less than 0.001 indicating that the overall effect of rank is statistically significant. 

```{r}
 hoslem.test(mylogit$y, fitted(mylogit), g=5)
```

The group number is set as 5 as the probit model. From the result of H-L test in Logistic model, we can see that the p-value is 4.263e-06 which is similar with the result in Probit model. We should take the result of wald-test and give up the result of unreliable H-L test. 














